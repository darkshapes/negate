# Advanced Configuration and Paths for Negate CLI

feat_ext_path = ""         # Path to save the model in or null for default: [$HOME/.cache/huggingface | C:/Users/USER/.cache/huggingface]
batch_size = 0             # Feature extraction batch size, 0 disables batching default[0]
dim_factor = 6             # Multiplier for image rescale size Default 6
dim_patch = 256            # Patch width for residuals (larger is faster, default 224 dinov2 256 dinov3 512 csat)
alpha = 0.25               # strength of perturbation Default 0.3)
dtype = "float16"          # decimal precision ("float64", "float32","float16", lower = <20% speed increase, less mem, slight accuracy hit)
residual_dtype = "float32" # decimal precision for numpy processing
load_onnx = false          # Use trained ONNX for inference : True → ONNX, False → native XGBoost
magnitude_sampling = true  # Process high/low freq only (True=dramatically faster+less accuracy, False=slower+more accurate
euclidean = false          # Substitute Cosine Similarity for Squared Euclidean Distance, (default false)
cache_features = false     # Cache features

[datasets]
eval_data = ["tellif/ai_vs_real_image_semantically_similar"]
genuine_data = ["KarimSayed/cat-breed-fiass-index"]
genuine_local = ["assets", "/Users/e6d64/Downloads/real_train"]
synthetic_data = ["exdysa/nano-banana-pro-generated-1k-clone", "ash12321/seedream-4.5-generated-2k"]
synthetic_local = ["/Users/e6d64/Downloads/phantomDiffusionS3FinalImages/", "/Users/e6d64/Downloads/syn_train"]

[train]
scale_pos_weight = ""              # Scale positive weight
seed = 0                           # Random seed
colsample_bytree = 0.8             # Column sample by tree
early_stopping_rounds = 10         # Early stopping rounds
export_model_path = "model"        # Path to save the model at
learning_rate = 0.1                # Learning rate
max_depth = 4                      # Maximum depth
n_components = 0.95                # Number of components for dimensionality reduction
num_boost_round = 200              # Number of boosting rounds
objective = "binary:logistic"      # Objective function
subsample = 0.8                    # Subsample ratio
top_k = 3                          # Highest percent threshold of patch difference to keep
eval_metric = ["logloss", "aucpr"] # Evaluation metrics

[model.library] # priority from left to right
timm = ["timm/vit_base_patch16_dinov3.lvd1689m"]
transformers = ["nvidia/C-RADIOv4-SO400M", "facebook/dinov3-vitl16-pretrain-sat493m"]
openclip = ["hf-hub:timm/MobileCLIP2-S4-OpenCLIP"]

[library]
default = "timm"
