# Advanced Configuration and Paths for Negate CLI

feat_ext_path = ""                     # Path to save the model in or null for default: [$HOME/.cache/huggingface | C:/Users/USER/.cache/huggingface]magnitude_sampling = true              # Process high/low only (True,fast++, less mem) or all (False, maybe more accurate) image frequencies
batch_size = 16                        # Feature extraction batch size, 0 disables batching (smaller = less memory, slightly slower)
dim_rescale = 1344                     # Fixed dimension
patch_dim = 224                        # Patch width for residuals (smaller is faster)
alpha = 0.5                            # strength of perturbation
model_dtype = "float32"                # decimal precision ("float64", "float32","bfloat16","float16", lower = less mem and accuracy)
numpy_dtype = "float32"                # decimal precision ("float64", "float32","float16", lower = slightly less mem and accuracy)
load_onnx = false                      # Use trained ONNX for inference : True → ONNX, False → native XGBoost
magnitude_sampling = false             # Process high/low freq only (True=dramatically faster+less accuracy, False=slower+more accurate

[datasets]
evaluation_data = ["tellif/ai_vs_real_image_semantically_similar"]
genuine_data = ["KarimSayed/cat-breed-fiass-index"]
genuine_local = ["assets", "/Users/e6d64/Downloads/real_train"]
synthetic_data = ["exdysa/nano-banana-pro-generated-1k-clone", "ash12321/seedream-4.5-generated-2k"]
synthetic_local = ["/Users/e6d64/Downloads/phantomDiffusionS3FinalImages/", "/Users/e6d64/Downloads/syn_train"]

[train]
scale_pos_weight = ""              # Scale positive weight
seed = 0                           # Random seed
colsample_bytree = 0.8             # Column sample by tree
early_stopping_rounds = 10         # Early stopping rounds
export_model_path = "model"        # Path to save the model at
learning_rate = 0.1                # Learning rate
max_depth = 4                      # Maximum depth
n_components = 0.95                # Number of components for dimensionality reduction
num_boost_round = 200              # Number of boosting rounds
objective = "binary:logistic"      # Objective function
subsample = 0.8                    # Subsample ratio
top_k = 3                          # Highest percent threshold of patch difference to keep
eval_metric = [
    "logloss", "aucpr",
    ] # Evaluation metrics

[model.library]                     # priority from left to right
transformers = ["facebook/dinov3-vitl16-pretrain-sat493m","nvidia/C-RADIOv4-SO400M"]
timm = ["timm/vit_base_patch16_dinov3.lvd1689m"]
openclip = ["timm/MobileCLIP2-S4-OpenCLIP"]


[library]
default = "timm"